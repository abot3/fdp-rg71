---
title: 'Final Project: Used Pickup Truck Price Prediction'
authors: "Aaron Botelho (botelho3), Shiyu Li (shiyuli2), Steven Johnson (stevenj4), Li Li (lil6)"
date: ''
output:
  html_document: 
    theme: readable
    toc: yes  
  pdf_document: default
urlcolor: cyan
---

***

```{r setup, echo = FALSE, message = FALSE, warning = FALSE}
options(scipen = 1, digits = 4, width = 80)
# TODO(anyone) - do we need to include install.packages commands e.g. tidyverse. 
library(knitr)
library(readr)
library(broom)
library(Metrics)
opts_chunk$set(cache = TRUE, autodep = TRUE)
source("Appendix/utility_functions.R")
source("Appendix/data_cleanup.R")
```

###### Aaron Botelho (botelho3), Shiyu Li (shiyuli2), Steven Johnson (stevenj4), Li Li (lil6)
```{r import_cleaned_data, include = FALSE}
set.seed(12345)
# TODO(anyone) - How should we import the csv data without adding it to the git repo?
# For now just copy the .csv into your local git directory?
truck_df = readr::read_csv("used_truck_data_with_region.csv")
spec(truck_df)

# TODO(anyone) - this should be replaced with the relevant parts of Appendix/data_cleanup.R.
# For now since I'm using used_truck_data_with_region.csv part of data_cleanup.R
# is already done.
# Edit - hmm the factorization part seems to be in set_data_structure() fn. Maybe 
# this works.
truck_df = set_data_structure(truck_df)

# A list of all columns that are _not_ characters or redundant columns
# (city, lat, long) in the data frame. The vector of column names can be used
# in formulas
no_char_columns = c(
  #X1 = col_double(),
  #dealer_zip = col_character(),
 "back_legroom" ,
  #bed" ,
  "bed_length" ,
  #cabin" ,
  #city" ,
  "city_fuel_economy" ,
  "daysonmarket" ,
  "engine_cylinders" ,
  "engine_displacement" ,
  "engine_type" ,
  "exterior_color" ,
  "fleet" ,
  "frame_damaged" ,
  "franchise_dealer" ,
  "front_legroom" ,
  "fuel_tank_volume" ,
  "fuel_type" ,
  "has_accidents" ,
  "height" ,
  "highway_fuel_economy" ,
  "horsepower" ,
  "interior_color" ,
  "isCab" ,
  "is_new" ,
  "latitude" ,
  "length" ,
  #listed_date = col_date(format = ""),
  #listing_color" ,
  "longitude" ,
  #make_name" ,
  "maximum_seating" ,
  "mileage" ,
  #model_name" ,
  "owner_count" ,
  "salvage" ,
  #"savings_amount" ,
  "seller_rating" ,
  "theft_title" ,
  "transmission" ,
  #transmission_display" ,
  "wheel_system" ,
  #wheel_system_display" ,
  "wheelbase" ,
  "width" ,
  "year" ,
  "power_hp" ,
  "power_rpm" ,
  "torque_lb_ft" ,
  "torque_rpm" ,
  "region" ,
  "state"
)
```

---

### Introduction
In this statistical study we have conducted an analysis of used pickup truck prices as a response to changes in variable data collected from scraping [Cargurus](https://www.cargurus.com/) inventory in September 2020. The dataset, which was pulled from [Kaggle](https://www.kaggle.com/ananaymital/us-used-cars-dataset), contains observations from the US used car market and was subset to isolate data by `body_type == Pickup Truck`. It was further tailored to highlight relevant variables that provide insights toward predicting our response variable, `price`.

The impetus for our carrying out this analysis was COVID-19. During the pandemic, with unprecedented migration between urban and rural centers, the prices of used vehicles experienced a notable surge. Additionally, the inventory of said vehicles declined in the US, up to 20% year-over-year in some regions. This piqued our interest as a great opportunity to explore significant indicators influencing used pickup truck prices throughout the states.

The prepared dataset is comprised of the following variables:

|Name   |Type   |Description   |
|:------|:------|:-------------|
|`back_legroom` |`num` |Legspace for backseat passengers in inches |
|`bed` |`Factor w/ 4 levels` |Type of truck bed (Long, Short, etc.) |
|`bed_length` |`num` |Length of truck bed in inches |
|`cabin` |`Factor w/ 5 levels`|Type of passenger cabin (Crew Cab, Extended Cab, etc.) |
|`city` |`Factor w/ 4060 levels` |City where vehicle is being sold |
|`city_fuel_economy` |`num` |MPG mileage in city |
|`daysonmarket` |`num` |Number of days listed for sale |
|`dealer_zip` |`Factor w/ 6897 levels` | Zip code of dealer |
|`engine_cylinders` |`Factor w/ 4 levels` |Number of engine cylinders (4, 6, 8, etc.) |
|`engine_displacement` |`num` |Engine displacement volume |
|`engine_type` |`Factor w/ 4 levels` |Number of engine cylinders (4, 6, 8, etc.) |
|`exterior_color` |`Factor w/ 10 levels` |Exterior color of vehicle |
|`fleet` |`logi` |- - - |
|`frame_damaged` |`logi` |Indicator for frame damage |
|`franchise_dealer` |`logi` |- - - |
|`front_legroom` |`num` |Legspace for frontseat passengers in inches |
|`fuel_tank_volume` |`num` |Capacity of the fuel tank |
|`fuel_type` |`Factor w/ 5 levels` |Type of fuel the vehicle uses to operate |
|`has_accidents` |`logi` |Indicator for whether or not the vehicle has been in an accident |
|`height` |`num` |Height of vehicle in inches |
|`highway_fuel_economy` |`num` |MPG mileage in highway |
|`horsepower` |`num` |Vehicle horsepower |
|`interior_color` |`Factor w/ 10 levels` |Interior color of vehicle |
|`isCab` |`logi` |- - - |
|`is_new` |`logi` |Indicator for a new car |
|`latitude` |`num` |Geographic latitude |
|`length` |`num` |Length of the vehicle in inches |
|`listed_date` |`chr` |Date vehicle was listed for sale |
|`listing_color` |`Factor w/ 10 levels` |Exterior color of vehicle |
|`longitude` |`num` |Geographic longitude |
|`make_name` |`Factor w/ 17 levels` |Manufacturer name |
|`maximum_seating` |`num` |Maximum number of seats in vehicle |
|`mileage` |`num` |Odometer reading |
|`model_name` |`chr` |Model of vehicle from manufacturer |
|`owner_count` |`num` |Number of previous owners |
|`price` |`num` |Sale price of used vehicle (Response) |
|`salvage` |`logi` |Indicator for vehicle being salvage |
|`savings_amount` |`num` |- - - |
|`seller_rating` |`num` |Consumer rating of vehicle seller |
|`theft_title` |`logi` |- - - |
|`transmission` |`Factor w/ 2 levels`|Automatic or Manual transmission (A or M) |
|`transmission_display` |`chr` |Transmission display within vehicle |
|`wheel_system` |`Factor w/ 5 levels` |Vehicle wheel-system (4WD, 4X2, 2WD, etc.) |
|`wheel_system_display` |`chr` |Vehicle wheel-system display within vehicle |
|`wheelbase` |`num` |Wheelbase width in inches |
|`width` |`num` |Width of vehicle in inches |
|`year` |`num` |Manufactured year of vehicle |
|`power_hp` |`num` |- - - |
|`power_rpm` |`num` |- - - |
|`torque_lb_ft` |`num` |Vehicle torque in foot pounds |
|`torque_rpm` |`num` |Vehicle torque RPM |
|`region` |`Factor w/ 9 levels` |US region of vehicle seller |
|`state` |`Factor w/ 49 levels` |State of vehicle seller |

In creating a linear regression model around these variables, we aim to (not only) identify the significant predictors of price for used pickup trucks, but to seek and potentially offer strategies for consumers to achieve the best value for their money.

---

### Methods
```{r}
# TODO
```

#### Data Cleaning
```{r}
# TODO
```


#### Outlier Analysis

```{r colinearity analysis}
# TODO(aaronbotelho, li)
```

```{r outlier_analysis_pt1 }
# Create a formual string for a simple additive model using all non-character columns
columns_of_interest = setdiff(no_char_columns, c("latitude", "longitude"))
no_char_additive_formula = formula(paste("price ~", paste("", columns_of_interest, sep = " ", collapse = " +")))
hist(truck_df$year, breaks=length(unique(truck_df$year)))
#rstandard 
#cooks.distance 
#2 Naive Models (mega model and “common” model) - Aaron or Anyone 
ofit0 = lm(no_char_additive_formula, data = truck_df)
summary(ofit0)
count_gt_stddev = c(length(which(rstandard(ofit0) > 1)),
  length(which(rstandard(ofit0) > 2)),
  length(which(rstandard(ofit0) > 3)),
  length(which(rstandard(ofit0) > 4)))
number_of_stddevs = c(1,2,3,4)
model_results = data.frame(number_of_stddevs, count_gt_stddev)
colnames(model_results) = c("# of stddev", "Count of rows > stddev")
knitr::kable(model_results)

# Do some Cook's distance tests. The intersection of high-outlier, 
# high-influence is 95%. Let's remove these from the dataset.
high_influence_rows = which(cooks.distance(ofit0) > 4/length(ofit0$residuals))
intersection_of_high_inf_high_outlier = intersect(which(rstandard(ofit0) > 4), high_influence_rows)
length(intersection_of_high_inf_high_outlier) / count_gt_stddev[4] 

# Let's take a look at the outlier rows to see if there's any commonality.
outlier_rows_to_remove = intersection_of_high_inf_high_outlier 
outlier_df = truck_df[outlier_rows_to_remove, ]
unique(truck_df[,"year"])
```

```{r refit with outliers removed.}
# Let's take a look at the outlier rows to see if there's any commonality.
outlier_rows_to_remove = intersection_of_high_inf_high_outlier 
outlier_df = truck_df[outlier_rows_to_remove, ]
# There's a modest improvement in R2 0.01 or 1%. The std error drops ~100. The
# fitted vs. residuals plot becomes waaaay more useful.
ofit1 = lm(price ~ year + I(year^2) + engine_displacement + mileage + I(mileage^2) +
   maximum_seating + wheel_system + power_hp + bed_length +
  frame_damaged + salvage,
   data = truck_df[-outlier_rows_to_remove, ])
summary(ofit1)
plot_fitted_resid(ofit1)
```


```{r}
rm(ofit1)
gc()
```

#### Discussion of Per - Region Models
```{r}
# Helper functions
#plot_fitted_resid = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
#  plot(fitted(model), resid(model), 
#       col = pointcol, pch = 20, cex = 1.5,
#       xlab = "Fitted", ylab = "Residuals")
#  abline(h = 0, col = linecol, lwd = 2)
#}
#
#plot_qq = function(model, pointcol = "dodgerblue", linecol = "darkorange") {
#  qqnorm(resid(model), col = pointcol, pch = 20, cex = 1.5)
#  qqline(resid(model), col = linecol, lwd = 2)
#}
#
#cal_rmse = function(model){
#  sqrt(mean(resid(model) ^ 2))
#}
#calc_loocv_rmse = function(model) { 
#   sqrt(mean((resid(model) / (1 - hatvalues(model))) ^ 2))
#}
```

```{r}
# Sherry’s Analysis + Discussion (including model per region, as it’s significant
# – but creates add’l work -- include sample of regions) - Sherry 
# Plots: F v R, QQ, normality hist (?) 
# Target metrics 
# bp & shapiro (improvement?) 

# Modeling for mid atlantic
cols_to_keep = append(intersect(no_char_columns, colnames(truck_df)), "price")
car_data = truck_df[, cols_to_keep]
mid_altantic_data = car_data[car_data$region == "Mid Atlantic",]
drops = c("region")
mid_altantic_data = mid_altantic_data[ , !(names(mid_altantic_data) %in% drops)]
# base model
base_altantic_model = lm(price ~ engine_displacement + engine_cylinders + highway_fuel_economy + horsepower+ maximum_seating + transmission + mileage + year + wheel_system + power_hp + bed_length + #cabin
                           + salvage + franchise_dealer, data = mid_altantic_data)
summary(base_altantic_model)
calc_loocv_rmse(base_altantic_model)
cal_rmse(base_altantic_model)
```

```{r}
# base model + state, state is significant
base_altantic_model_state = lm(price ~ engine_displacement + engine_cylinders + highway_fuel_economy + horsepower+ maximum_seating + transmission + mileage + year + wheel_system + power_hp + bed_length + #cabin
                                 + salvage + franchise_dealer + state, data = mid_altantic_data)
summary(base_altantic_model_state)
calc_loocv_rmse(base_altantic_model_state)
cal_rmse(base_altantic_model_state)
anova(base_altantic_model, base_altantic_model_state)
```

```{r}
# mega model
mega_midat_model = lm(price~., data =mid_altantic_data)
calc_loocv_rmse(mega_midat_model)
cal_rmse(mega_midat_model)
```

```{r}
# bic_model 
n = length(resid(mega_midat_model))
model_bic_midat = step(mega_midat_model, direction = "backward", k = log(n), trace = 0)
summary(model_bic_midat)
calc_loocv_rmse(model_bic_midat)
cal_rmse(model_bic_midat)
```

```{r}
improved_midat_model= lm(formula = price ~ back_legroom + bed_length  + 
    daysonmarket + franchise_dealer + fuel_tank_volume + 
    fuel_type + height + highway_fuel_economy + 
    horsepower + isCab + is_new + longitude + 
    maximum_seating + mileage + seller_rating + 
    wheel_system + wheelbase + width + 
    year  + torque_lb_ft + torque_rpm + state, data = mid_altantic_data)
summary(improved_midat_model)
calc_loocv_rmse(improved_midat_model)
cal_rmse(improved_midat_model)
```


#### ANOVA Analysis of Global Model
```{r}
#ANOVA analysis to reduce predictors (global) - Sherry 

```

#### Variable Transformations
```{r}
#Li wizardry with the log(price) transformation - Li 

```


---

### Results
```{r}
# Run prediction on Test data and present result analysis 

```

#### Significant Plots & Things
```{r}
# TODO
```

#### Non-Significant Plots & Things
```{r}
# TODO
```

---

### Discussion
```{r}
# TODO
```
 
---

### Appendix
```{r}
# TODO
```

***
